# Interview Prep <img src="https://media.giphy.com/media/WUlplcMpOCEmTGBtBW/giphy.gif" width="40">

## Table of Contents
- [Purpose of this guide](#purpose-of-this-guide)
- [Gaining Experience](#gaining-experience)
- [Mock Interviews](#mock-interviews)
- [Helpful Links](#misc-helpful-links)
- [Behavioral](#behavioral)
- [Questions for an Interviewer](#questions-for-an-interviewer)
- [Technical Questions Overview](#technical-questions-overview)
- [Language Questions](#language-questions)
	- [Python](#python)
	- [Java](#java)
	- [JavaScript](#javascript)
	- [Node.js](#node-js)
	- [Bash](#bash)
- [Docker](#docker)
- [Git](#git)
- [React](#react)
- [SQL / NoSQL](#sql-and-nosql)
- [Relational Databases](#relational-databases)
- [CI/CD](#ci-and-cd)
- [API Design](#api-design)
- [HTTP (Hypertext Transfer Protocol)](#http)
- [AWS](#aws)
- [Software Testing](#software-testing)
- [Parallel Processing](#parallel-processing)
- [System Design](#system-design-preparation)
- [Statistics and Probability](#statistics-and-probability)
- [Data](#data)
- [ML Prep](#ml-prep)
- [NLP](#nlp)
- [TODO](#todo)

---------------------------------

## Purpose of this guide:

:notebook_with_decorative_cover: This guide is intended to provide short info snippets on a variety of coding topics and the interview process. I have attempted to shorten guides to provide a quick studying experience, but some topics deserve a deeper dive through links provided. This is a work in progress. I hope you pass your interviews, become a better programmer, and land your dream job!!

<img align="center" width="190" height="190" src="https://media0.giphy.com/media/xT9DPIBYf0pAviBLzO/200w.webp?cid=ecf05e47wp3u03qd5ypxxp7zal7yp7fq8m5mvulj0dwk0huw&rid=200w.webp&ct=g">

---------------------------------

## Resume Help
Look up [Mayuko](https://www.youtube.com/watch?v=J5gy9iqjwXM&list=PLIin1ELTMmjYqKAYlb8Ll41c4Dl8PGgTD&index=7) and [Ken Jee](https://www.youtube.com/c/KenJee1) for the best resume advice  

## Applying
:keyboard: I recommend applying to as many places that fit your resume/skillset as possible and as early as possible.  
[best times to apply](https://betterprogramming.pub/the-software-engineering-application-timeline-f0b064927a1f)  

[Linkedin](https://www.linkedin.com/feed/) has expensive job postings so mostly big companies are posting and they are extremely competitive. Consider using [Indeed](https://www.indeed.com/) if you are strugging.  

Other good application sites include:
- [Tripe Byte](https://triplebyte.com/?ref=ga_20180823_search_brand_t1&gclid=EAIaIQobChMI77a43rS28wIVh4zICh2DVA58EAAYASAAEgJGA_D_BwE), [Crossover](https://www.crossover.com/), [Canvas](https://www.canvas.com/app/discover/jobs), [Angellist](https://angel.co/), [Smartr](https://www.smartr.me/)
- [Pathrise](https://www.pathrise.com/), [Sharpest minds](https://www.sharpestminds.com/landing-a-data-job-the-course)  

Try to add keywords to your linkedin profile, and make sure it is kept up to date. Recruiters will come to you and it is a great way to get a foot in the door. Pay attention to job descriptions and try to learn the skills and technologies to make yourself relevant to the field you would like to get into. Additionally reaching out through a well thought out message to a recruiter or manager may help you get an interview.  

[How to find Software Engineering job openings](https://www.youtube.com/watch?v=KObiuTFYTkM&list=PLIin1ELTMmjYqKAYlb8Ll41c4Dl8PGgTD&index=10)

**Motivation** 
* https://www.youtube.com/watch?v=kICh_d6tHQk&list=WL&index=1  
* https://www.youtube.com/watch?v=wlCz8nkDNqo&list=WL&index=7

## Last Step
:tada: Congratulations!! :tada:  <img align="center" width="50" height="50" src="https://media0.giphy.com/media/PxqXdxK85QWmk/200.webp?cid=ecf05e47k5ofp5ul94jnl7sdjw0da5gi1zv4fyfvizqxum42&rid=200.webp&ct=g)">  
[Negotiating an offer](https://www.youtube.com/watch?v=u9BoG1n1948&list=PLIin1ELTMmjYRmbQo_fYwU2vWtaK5CXxp&index=25)  
[Level.fyi](https://www.levels.fyi/?compare=Google,Facebook,Microsoft&track=Software%20Engineer)

## Gaining Experience:
Expanding your resume/portfolio:  
- [Kaggle](kaggle.com)
- Creating a RESTful API
- Web applications (with persistent memory)
- SQL analysis (tableau, powerbi)
- :octocat: Contributing to [open source](https://github.com/firstcontributions/first-contributions) projects - look for good first issue tags
- :books: I would suggest using the book Cracking the Coding Interview and [Leetcode](https://leetcode.com/problemset/all/) for technical practice

## Misc helpful links:
[Leetcode](https://leetcode.com/problemset/all/) - best technical problem source **(use this!)**
[Codewars](https://www.codewars.com/kata/search/my-languages?q=&&beta=false&order_by=popularity%20desc) -easier problems

[Coding Interview Help](https://github.com/jwasham/coding-interview-university)  
[Related Interview Help Flash Cards](https://github.com/jwasham/computer-science-flash-cards)  

https://github.com/Olshansk/interview#readme  
https://github.com/schmatz/cs-interview-guide  
https://github.com/donnemartin/interactive-coding-challenges  
https://github.com/donnemartin/system-design-primer   

### Data Science / Analytics links:  
- [Mode (SQL)](https://mode.com/sql-tutorial/), [strataScratch](https://www.stratascratch.com/)

https://github.com/cdeweyx/DS-Career-Resources/blob/master/Interview-Resources.md  
[Great Big Data Cookbook](https://github.com/andkret/Cookbook)  
[Linkedin Data Analytics help](https://business.linkedin.com/talent-solutions/resources/interviewing-talent/data-analyst)  

**Google Learning Resources**  
> https://developers.google.com/learn  
> https://developers.google.com/machine-learning/crash-course  
> https://developers.google.com/learn/pathways  

**Random Helpful Articles**
https://raft.github.io/  
[List of great github profile readmes](https://github.com/codeSTACKr/awesome-github-profile-readme)

----------------------------------------------------------------

## Mock interviews:
https://interviewing.io/  
https://www.pramp.com/#/  
https://www.swecareers.com/mock-interviews  

**Example Coding Interviews:**  
https://www.youtube.com/watch?v=4tYoVx0QoN0&list=PLIin1ELTMmjYqKAYlb8Ll41c4Dl8PGgTD&index=3  
https://www.youtube.com/watch?v=10WnvBk9sZc&list=PLIin1ELTMmjYqKAYlb8Ll41c4Dl8PGgTD&index=4&t=344s  
https://www.youtube.com/watch?v=HWW-jA6YjHk&list=PLIin1ELTMmjYqKAYlb8Ll41c4Dl8PGgTD&index=5&t=126s

## Favorite Youtube Creators:
- https://www.youtube.com/c/Fireship -Random Tech Tutorials
- https://www.youtube.com/c/hellomayuko -SWE Interview Questions
- https://www.youtube.com/c/Reducible -SWE Interview Questions
- https://www.youtube.com/channel/UC2UXDak6o7rBm23k3Vv5dww -Data Science Creator Tina Huang
- https://www.youtube.com/c/KenJee1 -Data Science Creator Ken Jee
- https://www.youtube.com/c/3blue1brown -Math Creator 3blue1brown
- https://www.youtube.com/c/AbhishekThakurAbhi -Best ML competitor Abhishek Thakur

----------------------------------------------------------------
## Behavioral:

> Most behavioral interviews are 15-30 minutes long and are inquiries into your personality and experience. They may throw in some 'trivia' questions on things they are looking for. Some behavioral interviews also involve walking through a past project or two. Make sure to maintain good documentation and know every part of your projects.

**Tell me about yourself:**  
  - Current Role (your headline) 
  - College  
  - Post College / Current Role  
  - Outside of work (how are you upskilling?)  

Two optional additions: Career goal, a unique fact about yourself  

What do you know about ___ and why did you decide to apply here?  What drew you to us?
- Research company you're applying to
	- Work environment
	- Growth potential
	- type of work

What makes you a good fit for the company? 

What are you looking for?  

What are the things that are most important to you in a job?

#### Can you tell me about a time that you ---?  
When answering a question about a past experience it is best to use either a nugget first method or the STAR method to best tell the tale.
> **Nugget first:** Start with a nugget that succincly describes what your response will be about.
> 
> **STAR** method
> - Situation / Task -> Action -> Result
	
Tell me about a time where you had to persuade a group of people to make a change.

Describe a conflict you had with a team member. How did you handle the conflict and what was the outcome? 

Tell me about a time where you dealt with ambiguity.

Tell me about a time where you demonstrated leadership skills.  

What do you do when faced with adversity?

How do you handle working under pressure?

Do you enjoy working alone or on a team more?

How would your boss describe you?

Tell me your greatest strength and weakness.

How do you approach a new project and technology? :test_tube:
- Look at similar project examples
- Examine why they used the technology
- Read documentation explaining things
- Get hands on and try tutorials and experiment
	
## Questions for an interviewer: 
It is important to ask questions during and at the end of an interview, try one of these :speech_balloon:
- What would my normal day look like?
- Can you tell me about whom I will be working with?
- How is mentorship approached?
- What would be your definition of success for this role?
- What is your tech stack?
- Do you enjoy your role in the company? What do you enjoy about your job?
- Do you like your company?
- What brought you to this company?
- Remote work?
- What are the standard working hours?
- How long is the interviewing process?
- What is the growth potential for me?

----------------------------------------------------------

## Technical Questions Overview:

> A technical interview usually consists of solving two problems infront of another engineer on a whiteboard or through a take home assessment with 3+ problems. It is integral to talk to the intervier about the problem and your thought process. Try using pseudocode at the start to get yourself orientated. Understanding Big-O notation will also help you in the interview and to be a better programmer.

https://www.youtube.com/watch?v=YBSt1jYwVfU&list=PLIin1ELTMmjYRmbQo_fYwU2vWtaK5CXxp&index=1   
https://www.youtube.com/watch?v=GBuHSRDGZBY&list=WL&index=14&t=853s  
https://www.youtube.com/watch?v=aPQY__2H3tE&list=WL&index=13

#### General Technical 'Trivia' and Fundamentals
> I have found technical trivia sometimes thrown into behavioral interviews these are some of them. They are also important to know for coding.

What is an **Object** and a **Class**, what's the difference between them?  
- A **class** is a template for objects. A class defines object properties and behaviors, including a valid range of values, and a default value  
- An **object** is a member or an "instance" of a class. An object has a state in which all of its properties have values that you either explicitly define or that are defined by default  

What are the pillars of **OOP?**
- **Abstraction- ability to hide things
- **Encapsulation**- binding data and functions for protection
- **Inheritance**- inheriting features of parent class
- **Polymorphism**- the ability to redefine methods for derived classes

What is method **overloading** and **overriding**?  
**Overloading:** when two or more methods in the same class share a name, but not parameters  
**Overriding:** When name and parameters of method are the same  

**Recursion:**
- A function which calls itself recursively
- Consists of a base case (stopper) and a recursive case(recurser)

What's the difference between a stack and a queue?  
- Stacks "pop" data off the stack, using last-in first out (LIFO) (ex: books/pancakes)
- Queues use first-in, first-out (FIFO) (think of a pipe)

What do you look for when reviewing code?
- **B** ottlenecks
- **U** nnecessary work
- **D** uplicated work

----------------------------------------------------------------

I am working on filling out this section, but this is likely the **most important** section for a technical interview. Mastering your data structures and algorithms will help you solve any problem thrown at you.

**Big O Notation: [Coding-interview university](https://github.com/jwasham/coding-interview-university#algorithmic-complexity--big-o--asymptotic-analysis)** :point_left: super important

- [Dynamic Programming](https://leetcode.com/tag/dynamic-programming) + Recursion:
- [BFS](https://leetcode.com/tag/breadth-first-search) and [DFS](https://leetcode.com/tag/depth-first-search):
- [Trees:](https://leetcode.com/tag/tree)
- [Linked lists:](https://leetcode.com/tag/linked-list)	
- [Stacks:](https://leetcode.com/tag/stack)
- [Heaps / Priority Queues:](https://leetcode.com/tag/heap-priority-queue)
- [Binary Search:](https://leetcode.com/tag/binary-search) [leetcode article](https://leetcode.com/discuss/general-discussion/786126/python-powerful-ultimate-binary-search-template-solved-many-problems)
- [Two Pointers:](https://leetcode.com/tag/two-pointers)
- [Divide and Conquer:](https://leetcode.com/tag/divide-and-conquer)
- [Hashing/dictionaries:](https://leetcode.com/tag/hash-table)
- [Greedy Algorithms:](https://leetcode.com/tag/greedy)
- [Backtracking:](https://leetcode.com/tag/backtracking)
- Sliding Window:
- [Union Find:](https://leetcode.com/tag/union-find)
- [Graphing:](https://leetcode.com/tag/graph)
- [Sorting Algorithms:](https://leetcode.com/tag/sorting) (Quick, Merge, Selection, Tim)
- [Bit Manipulation:](https://leetcode.com/tag/bit-manipulation)

- [SQL](https://leetcode.com/tag/database/): [Mode (SQL)](https://mode.com/sql-tutorial/), [strataScratch](https://www.stratascratch.com/)

----------------------------------------------------------------

# Language Questions:

## Python: 
<img align="center" width="50" height="50" src="https://media2.giphy.com/media/KAq5w47R9rmTuvWOWa/200.webp?cid=ecf05e47hdcr00jhebditkzbcaqzdz21zscu1k45jdhirjvg&rid=200.webp&ct=g">  

**Python** is a high-level, interpreted, dynamically typed, general-purpose programming language.  

:spiral_notepad: [Python](https://www.w3schools.com/python/) is my go to technical interview language as it is beatiful, pythonic, and relatively easy. I highly recommend you learn it and use it in your interviews.

What are **lists** and **tuples** and what are their differences?:  
- Both sequence data types (can hold multiple types)
- **Lists** are mutable - changeable
- **Tuples** are immutable

Understanding [list comprehensions](https://www.w3schools.com/python/python_lists_comprehension.asp) and [slicing](https://www.w3schools.com/python/python_strings_slicing.asp) will make your life a lot easier.

**Lambda** is an anonymous function in Python that can accept any number of arguments, but can only have a single expression. It is generally used in situations requiring an anonymous function for a short time period.

**__init__** is a constructor method in Python and is automatically called to allocate memory when a new object/instance is created. All classes have a __init__ method associated with them. It helps in distinguishing methods and attributes of a class from local variables.

**Self** is a keyword in Python used to define an instance or an object of a class. In Python, it is explicitly used as the first parameter, unlike in Java where it is optional. It helps in distinguishing between the methods and attributes of a class from its local variables

**Decorators** in Python are essentially functions that add functionality to an existing function in Python without changing the structure of the function itself. They are represented by the @decorator_name in Python and are called in bottom-up fashion.

*args can be used to pass multiple  positional arguments
**kwargs can be used to pass multiple  keyword/named arguments

**Functions** are first-class objects. This means that they can be assigned to variables, returned from other functions and passed into functions. Classes are also first class objects

**PEP8:** Python Enhancement Proposal. It is a set of rules that specify how to format Python code for maximum readability.

----------------------------------------------------------------

## JavaScript:

JavaScript is a high level interpreted oop language that is single threaded (no parallelism). It is dynamically typed, and has first-class functions. Multiparadigm language supports: event-driven, functional, and imperative programming styles. Sets the behavior of web pages.

https://www.youtube.com/watch?v=6Wzj7kxfRdI

What is the difference between *let* and *var*?
- The *let* statement declares a block scope local variable. Hence the variables defined with let keyword are limited in scope to the block, statement, or expression on which it is used. Whereas variables declared with the *var* keyword used to define a variable globally, or locally to an entire function regardless of block scope.

Events are "things" that happen to HTML elements. When JavaScript is used in HTML pages, JavaScript can react to these events.

What is a **prototype** in javascript?
- All javascript objects inherit properties and methods from a prototype.

What is the meaning of the keyword ***this*** in javascript?
- ***This*** is a reference to the object it belongs to

What is a **promise** and what is a **callback?**
- A **promise** is an object that may produce a single value some time in the future with either a resolved value or a reason that it’s not resolved(for example, network error). It will be in one of the 3 possible states: fulfilled, rejected, or pending.
- A **callback** function is a function passed into another function as an argument. This function is invoked inside the outer function to complete an action.

What does === do in JavaScript?

https://github.com/sudheerj/javascript-interview-questions#what-is-a-prototype-chain

---------------------------------------------------------------------------

## Java 

**Java** is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is a general-purpose programming language intended to let application developers write once, run anywhere (WORA)

Unlike C++, Java does not support operator overloading or multiple inheritance for classes, though multiple inheritance is supported for interfaces.

The keyword **public** denotes that a method can be called from code in other classes, or that a class may be used by classes outside the class hierarchy. The class hierarchy is related to the name of the directory in which the .java file is located. This is called an access level modifier. Other access level modifiers include the keywords **private** (a method that can only be accessed in the same class) and **protected** (which allows code from the same package to access). If a piece of code attempts to access private methods or protected methods, the JVM will throw a SecurityException

The keyword **static** in front of a method indicates a static method, which is associated only with the class and not with any specific instance of that class. Only static methods can be invoked without a reference to an object. Static methods cannot access any class members that are not also static. Methods that are not designated static are instance methods and require a specific instance of a class to operate.

The keyword **void** indicates that the main method does not return any value to the caller. If a Java program is to exit with an error code, it must call System.exit() explicitly.

The method name **main** is not a keyword in the Java language. It is simply the name of the method the Java launcher calls to pass control to the program. A Java program may contain multiple classes that have main methods, which means that the VM needs to be explicitly told which class to launch from.

What is a **singleton class** in java?
- A **singleton class** is a class that can have only one object (an instance of the class) at a time. After the first time, if we try to instantiate the Singleton class, the new variable also points to the first instance created.

![JVM](https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/JvmSpec7.png/220px-JvmSpec7.png)

---------------------------------------------------------------------------

## Node js

A backend JavaScript runtime environment which can execute javaScript outside of a web browser. Node lets you use command line tools and for server-side scripting where dynamic web page content is produced before the page is sent to the user’s browser.

Here is how PHP or ASP handles a file request:
1. Sends the task to the computer's file system.
2. Waits while the file system opens and reads the file.
3. Returns the content to the client.
4. Ready to handle the next request.

Here is how Node.js handles a file request:
1. Sends the task to the computer's file system.
2. Ready to handle the next request.
3. When the file system has opened and read the file, the server returns the content to the client.  
Node.js eliminates the waiting, and simply continues with the next request.

Node.js runs single-threaded, non-blocking, asynchronous programming, which is very memory efficient.
- Node.js can generate dynamic page content
- Node.js can create, open, read, write, delete, and close files on the server
- Node.js can collect form data
- Node.js can add, delete, modify data in your database

--------------------------------------------------------------------------

## Bash

The Bourne Again SHell. It is a Unix shell and command language.  
https://www.gnu.org/software/bash/manual/bash.html#What-is-Bash_003f

It offers functional improvements over sh for both programming and interactive use. In addition, most sh scripts can be run by Bash without modification.
The improvements offered by Bash include:
- command-line editing,
- unlimited size command history,
- job control,
- shell functions and aliases,
- indexed arrays of unlimited size,
- integer arithmetic in any base from two to sixty-four.  

Example commands:
	Cd, break, continue, exec.
	
**Name:** 
A word consisting solely of letters, numbers, and underscores, and beginning with a letter or underscore. Names are used as shell variables and function names. Also referred to as an identifier.

--------------------------------------------------------------------------

## Docker
Docker is an open platform for developing, shipping, and running applications. Docker provides the ability to package and run an application in a loosely isolated environment called a container. https://docs.docker.com/get-started/overview/#the-docker-daemon

![Docker](https://docs.docker.com/engine/images/architecture.svg)

**Docker architecture**  
Docker uses a client-server architecture. The Docker client talks to the Docker daemon, which does the heavy lifting of building, running, and distributing your Docker containers. The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface. Another Docker client is Docker Compose, which lets you work with applications consisting of a set of containers.

**The Docker daemon**  
The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.

**The Docker client**  
The Docker client (docker) is the primary way that many Docker users interact with Docker. When you use commands such as docker run, the client sends these commands to dockerd, which carries them out. The docker command uses the Docker API. The Docker client can communicate with more than one daemon.

**Docker registries**  
A Docker registry stores Docker images. Docker Hub is a public registry that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can even run your own private registry.

When you use the docker pull or docker run commands, the required images are pulled from your configured registry. When you use the docker push command, your image is pushed to your configured registry.

**Docker objects**  
When you use Docker, you are creating and using images, containers, networks, volumes, plugins, and other objects.

**Images**  
An image is a read-only template with instructions for creating a Docker container. Often, an image is based on another image, with some additional customization. For example, you may build an image which is based on the ubuntu image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.

You might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a Dockerfile with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.

**Containers**  
A container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI. You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.

By default, a container is relatively well isolated from other containers and its host machine. You can control how isolated a container’s network, storage, or other underlying subsystems are from other containers or from the host machine.

A container is defined by its image as well as any configuration options you provide to it when you create or start it. When a container is removed, any changes to its state that are not stored in persistent storage disappear.

------------------

## Git
Git is an additive version control system used to aid cooperation on projects. It is usually used in conjunction with [Github](https://github.com/). Git and Github are almost ubiquitiously used by tech companies and is extremely useful to learn. Github is a great place to host your portfolio and demonstrate your knowledge through commits.    

![git ex](https://tutorialslink.com/Article_img/Blog_image/a0f60344-2db5-4f1c-bde7-2abd7fe8b96c.png)

[Git book](https://git-scm.com/book/en/v2)  

[Contributing to your first open source project](https://github.com/firstcontributions/first-contributions)  

**Markdown help:**
> [Markdown Cheatsheet (general)](https://wordpress.com/support/markdown-quick-reference/)
> [Mastering markdown](https://guides.github.com/features/mastering-markdown/)
> [List of great github profile readmes](https://github.com/codeSTACKr/awesome-github-profile-readme)
> [Emoji Cheatsheet](https://github.com/ikatyang/emoji-cheat-sheet/blob/master/README.md#objects) :heart_eyes:  

**Helpful Videos:**
- [100 second git summary](https://www.youtube.com/watch?v=hwP7WQkmECE)
- [Learn git in 15 min](https://www.youtube.com/watch?v=USjZcfj8yxE&list=PLIin1ELTMmjYRmbQo_fYwU2vWtaK5CXxp&index=3&t=305s)

My initial project workflow: :octocat:
- git init repo in directory
- git add files
- git status
- git commit -m "asdf"
- git pull origin master (if remote branch chaged)
- git push -u origin master

--------------------------------------------------
## SQL and NoSQL

Format of a SQL query:
- SELECT
- FROM
- WHERE
- GROUP BY
- HAVING
- ORDER BY

What are the sql aggregate functions?
- COUNT
- MAX/MIN
- AVG
- GROUP BY
- CASE
- DISTINCT
- JOINS

What are the different types of joins and can you explain them?  

What is a view?  

What are entities and relationships?

https://www.interviewbit.com/sql-interview-questions/

SQL | NoSQL
------------ | -------------
vertically scalable | horizontally scalable
table based | document, key-value, graph or wide-column stores
better for multi-row transactions | better for unstructured data like documents or JSON
  
https://www.youtube.com/watch?v=W2Z7fbCLSTw&list=PLIin1ELTMmjYRmbQo_fYwU2vWtaK5CXxp&index=40  

-----------------------------------

## Relational Databases:

**Primary Key (PK):**  
A column with a unique value for each row. Although not all database management systems (DBMS) require you to put a PK into each table, from a design perspective a PK is a requirement. No table should be without one.

**Foreign Key (FK):**  
These define relationships between tables. When you want a row in one table to be linked to a row in another table, you place a FK column in the child table and use the value of the parent row's PK as the value of the FK field.

**Composite Key:**  
This is a key that is made up of more than one column. This is typically used when you want to prevent a table from using the same combination of values twice. For example, in a table that lists item prizes for shops, you would only want each shop to have a single price for each item. So, you create a FK for the shop and a FK for the item, and then you create a composite PK out of those two columns. This would cause the DBMS to forcefully restrict entries that would create rows where the combined values of these fields are duplicated. - This type of key is commonly used in N:M relationships.

**One-To-One (1:1) relationship:**  
A relationship between two tables, where a single row in one table is linked to a single row in another table.  
This type of relationship is practically non-existent in normalized relational designs. They exist mostly to get around limitations in databases like Access, where the number of columns was limited, thus creating the need to split tables up. They are also sometimes used to optimize the performance of the database.

**One-To-Many (1:N) relationship:**  
A relationship between two tables, where multiple rows in a child table can be linked to a single row in a parent table.
This is in fact the only "real" type of relationship in a relational database.

**Many-To-Many (N:M) relationship:**  
A relationship between two tables, where multiple rows in one table can be linked to multiple rows in another table. This type is "artificial" in a a way, because this kind of relationship can not be created directly between tables. To accomplish this type of relationship you need to create a third table; an intermediary table that contains FKs to both parents, linked via a set of 1:N relationships.

## Normalization:  
To help us properly design our tables we have a set of guidelines which, if followed properly, will help reduce the redundancy and chance of data corruption. We call this "Normalization". 
https://www.dreamincode.net/forums/topic/179103-relational-database-design-normalization/  
https://dba.stackexchange.com/questions/4622/when-should-you-denormalize/15798#15798  

There are several steps involved in normalizing a database. The steps are referred to as "Normal Forms". There are at least 7 NF. Each NF requires that the NF before it has also been satisfied. The spot between 3NF and 4NF is reserved for the BCNF (Boyce-Codd normal form), which was developed later as a slightly stronger version of the 3NF. Tables that have reached the 3NF are generally considered "normalized".  
- 1NF: tables must not contain repeating groups of data
- 2NF: no field should only be partially dependent on any candidate key
- 3NF: columns should depend only upon the primary key of the table

**B-Tree**  
A self balancing tree used as a database
http://20bits.com/article/interview-questions-database-indexes

## ETL (Extract, Transform, Load)  
Extract Transform Load is the procedure for copying data into a different system. We do this to gather and clean data and transfer the data into an easily stored and queryable form.

## MapReduce

## Data Pipeline

----------------------------

## CI and CD

https://www.redhat.com/en/topics/devops/what-is-ci-cd  
Jenkins

-----------------------------------------------------

## API Design:

**RESTful API**:
- An architectural style for an application program interface (API) that uses HTTP requests to access and use data. That data can be used to GET, PUT, POST and DELETE data types, which refers to the reading, updating, creating and deleting of operations concerning resources.

REST = REpresentational State Transfer

**CRUD** : for persistent data
- Create = post
- Read = get
- Update = put
- Delete = delete

- GET to retrieve a resource;
- PUT to change the state of or update a resource, which can be an object, file or block;
- POST to create that resource; and
- DELETE to remove it.

**Persistence** is said to be ["orthogonal"](https://en.wikipedia.org/wiki/Orthogonality#Computer_science) or "transparent" when it is implemented as an intrinsic property of the execution environment of a program. An orthogonal persistence environment does not require any specific actions by programs running in it to retrieve or save their state.

**Non-orthogona**l persistence requires data to be written and read to and from storage using specific instructions in a program, resulting in the use of persist as a transitive verb: On completion, the program persists the data.
The advantage of orthogonal persistence environments is simpler and less error-prone programs

**GraphQL:**
- A query/manipulation language for your API and a runtime for fulfilling queries with existing data

**OLTP vs OLAP** 
- [link](https://techdifferences.com/difference-between-oltp-and-olap.html#:~:text=OLTP%20and%20OLAP%20both%20are,is%20an%20analytical%20processing%20system.&text=The%20basic%20difference%20between%20OLTP,online%20database%20query%20answering%20system.)
- Both are online processing systems. OLTP is a transactional processing sys which modifies data while OLAP is an analytical processing system which queries.

------------------------------------------------------

## HTTP 
**(Hypertext Transfer Protocol)**

([HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP)) is an [application-layer](https://en.wikipedia.org/wiki/Application_Layer) protocol for transmitting hypermedia documents, such as HTML. It was designed for communication between web browsers and web servers, but it can also be used for other purposes. HTTP follows a classical [client-server model](https://en.wikipedia.org/wiki/Client%E2%80%93server_model), with a client opening a connection to make a request, then waiting until it receives a response. HTTP is a [stateless protocol](https://en.wikipedia.org/wiki/Stateless_protocol), meaning that the server does not keep any data (state) between two requests. Though often based on a TCP/IP layer, it can be used on any reliable [transport layer](https://en.wikipedia.org/wiki/Transport_Layer), that is, a protocol that doesn't lose messages silently like UDP does. RUDP — the reliable update of UDP — is a suitable alternative.

![http](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/http-layers.png)

http vs https:  
![httpvshttps](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.tutorialsmate.com%2F2020%2F07%2Fhttp-vs-https.html&psig=AOvVaw11Yu_ZmorklJJ1s8OaixnV&ust=1633460155989000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCIjjzbW3sfMCFQAAAAAdAAAAABAK)

https://www.tutorialspoint.com/http/http_overview.htm
 
Caching: https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching
 
**Cookies:** :cookie:
- a small piece of data that a server sends to the user's web browser. The browser may store it and send it back with later requests to the same server. Typically, it's used to tell if two requests came from the same browser — keeping a user logged-in, for example. It remembers stateful information for the stateless HTTP protocol.
 
**Cookies** are mainly used for three purposes:
- **Session management**
	- Logins, shopping carts, game scores, or anything else the server should remember
- **Personalization**
	- User preferences, themes, and other settings
- **Tracking**
	- Recording and analyzing user behavior

[How a browser works](https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/)

## HTTP request methods (HTTP verbs):

Indicate the desired action to be performed for a given resource. Each of them implements a different semantic, but some common features are shared by a group of them: e.g. a request method can be [safe](https://developer.mozilla.org/en-US/docs/Glossary/Safe), [idempotent](https://developer.mozilla.org/en-US/docs/Glossary/Idempotent), or [cacheable](https://developer.mozilla.org/en-US/docs/Glossary/cacheable).

- GET
	- The GET method requests a representation of the specified resource. Requests using GET should only retrieve data.
- HEAD
	- The HEAD method asks for a response identical to that of a GET request, but without the response body.
- POST
	- The POST method is used to submit an entity to the specified resource, often causing a change in state or side effects on the server.
- PUT
	- The PUT method replaces all current representations of the target resource with the request payload.
- DELETE
	- The DELETE method deletes the specified resource.
- CONNECT
	- The CONNECT method establishes a tunnel to the server identified by the target resource.
- OPTIONS
	- The OPTIONS method is used to describe the communication options for the target resource.
- TRACE
	- The TRACE method performs a message loop-back test along the path to the target resource.
- PATCH
	- The PATCH method is used to apply partial modifications to a resource.

**WebSockets:**
- Provide a persistent connection between a client and server that both parties can use to start sending data at any time.  
https://blog.teamtreehouse.com/an-introduction-to-websockets

The client establishes a WebSocket connection through a process known as the WebSocket handshake. This process starts with the client sending a regular HTTP request to the server. An Upgrade header is included in this request that informs the server that the client wishes to establish a WebSocket connection.

Here is a simplified example of the initial request headers.
> - GET ws://websocket.example.com/ HTTP/1.1
> - Origin: http://example.com
> - Connection: Upgrade
> - Host: websocket.example.com
> - Upgrade: websocket

## TCP/IP

## Model View Controller (MVC)    

- Model
	- The central component of the pattern. It is the application's dynamic data structure, independent of the user interface. It directly manages the data, logic and rules of the application. It receives user input from the controller.
- View
	- Any representation of information such as a chart, diagram or table.
- Controller
	- Accepts input and converts it to commands for the model or view  
![mvc](https://developer.mozilla.org/en-US/docs/Glossary/MVC/model-view-controller-light-blue.png)

------------------------------------------------------
## AWS

### Amazon Web Services / Cloud Data Principles

I took the [AWS cloud practioner ceritification](https://aws.amazon.com/certification/certified-cloud-practitioner/?trk=ps_a134p000006gXRtAAM&trkCampaign=GLBL-FY21-TrainCert-Certification_PaidSearch&sc_channel=PS&sc_campaign=FY21-TrainCert-Certification_PaidSearch&sc_publisher=Google&sc_category=Training%20and%20Certification&sc_country=US&sc_geo=NAMER&sc_outcome=acq&sc_detail=aws%20cloud%20practitioner%20certification&sc_content=Cloud%20Practitioner%20Solution_exact&sc_matchtype=e&sc_segment=508672713544&sc_medium=TC-P|PS-GO|Brand|Desktop|AW|Training%20and%20Certification|Certification|US|EN|Text|xx|B2I&s_kwcid=AL!4422!3!508672713544!e!!g!!aws%20cloud%20practitioner%20certification&ef_id=EAIaIQobChMIut-plvi48wIVmIjICh0E6AobEAAYAiAAEgJ7EPD_BwE:G:s&s_kwcid=AL!4422!3!508672713544!e!!g!!aws%20cloud%20practitioner%20certification) and [passed](https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A6847536534841802752?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3B4YYhEMILRXCVKvM4uhpanw%3D%3D) after two days of studying mainly using resources provided by AWS. This is the easiest AWS certification, but there are a lot of general pieces of knowledge needed to pass it.

**Serverless:** an AWS architectural design principle based, where developers focus on the applications that they want to put into AWS resources, and serverless solutions such as AWS Lambda will then interpret the application and provision the compute and storage power required for execution.

**Virtual Private Cloud (VPC):****
a plot of virtual space within the Amazon Cloud to work within. A user or account may have many VPCs, but must have at least one VPC to act as a designated workspace to house your AWS cloud resources. VPC is a backbone principle of AWS cloud architecture, and they can connect to one another to create complex private and public networks. VPC has 4 main subcomponents – SUBNET, INTERNET GATEWAY, ROUTE, TABLE, NETWORK ACCESS CONTROL LIST (NACL).

**Elastic Compute Cloud (EC2):** a scalable computing capacity or virtual machine (VM) powered by AWS. A backbone resource of AWS that supports application hosting, remote network logins and gateways, database hosting and more.

**Simple Storage Service (S3):** has a simple web services interface that you can use to store and retrieve any amount of data, at any time, from anywhere on the web. This data is stored in buckets, and you pay as you go for the size of storage you need. S3 is not able to be queried like a database and is not designed for frequent or mass request access. S3 buckets can be used to house the files such as HTML, JS, and CSS for a static web site, and then host that static website.

**Relational Database Service (RDS):** RDS makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups. It frees you to focus on your applications so you can give them the fast performance, high availability, security and compatibility they need. Amazon RDS is available on several database instance types - optimized for memory, performance or I/O - and provides you with six database engines to choose from, including Aurora, PostgreSQL, MySQL, MariaDB, Oracle Database, and SQL Server.

**Amazon Aurora:** is a MySQL/PostgreSQL compatible relational database built for the cloud. Aurora is up to 5x faster than standard MySQL databases and 3x faster than standard PostgreSQL databases. Aurora is fully managed by Amazon (RDS), which automates time-consuming administration tasks like hardware provisioning, database setup, patching, and backups. Aurora features a distributed, fault-tolerant, self-healing storage system that auto-scales up to 128TB per database instance. It delivers high performance and availability with up to 15 low-latency read replicas, point-in-time recovery, continuous backup to Amazon S3, and replication across 3(AZs).

**Elastic Block Store (EBS):** is a block-storage service designed for use with Amazon Elastic Compute Cloud (EC2) for both throughput and transaction intensive workloads at scale. A broad range of workloads, such as relational and non-relational databases, enterprise applications, containerized applications, big data analytics engines, file systems, and media workflows are deployed on Amazon EBS. You may only mount one EC2 to an EBS at a time. Designed for mission-critical systems, EBS volumes are replicated within an Availability Zone (AZ) and can easily scale to petabytes of data. Also, you can use EBS Snapshots with automated lifecycle policies to back up your volumes in S3, while ensuring geographic protection of your data and business continuity.

**Elastic File System (EFS):** a network file system (NFS), that is scalable and fully managed by AWS. Amazon EFS is designed to provide massively parallel shared access to thousands of Amazon EC2 instances. Customers can use EFS to lift-and-shift existing enterprise applications to the AWS Cloud. Other use cases: big data analytics, web serving and content management, application development and testing, media workflows, database backups, and container storage. EFS is a regional service storing data within and across multiple (AZs) for high availability and durability. Amazon EC2 instances can access your file system across AZs, regions, and VPCs, while on-premises servers can access using AWS Direct Connect or AWS VPN. Not supported for Windows EC2 Instances.

**FSx:** see above EFS. Comparable to EFS but built on Windows Server and supports Windows EC2, Linux, and MacOS Compute Instances.

**Identity and Access Management (IAM):** AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions.

**AWS Lambda:** is a serverless compute service that lets you run code without provisioning ormanaging servers, creating workload-aware cluster scaling logic, maintaining event integrations, or managing runtimes. Just upload your code as a ZIP file or container image, and Lambda allocates compute execution power and runs your code based on the incoming request or event. You can set up your code to automatically trigger from 140 AWS services or call it directly. You can write Lambda functions in any language and use both serverless and container tools, such as AWS SAM or Docker CLI, to build, test, and deploy your Functions.

**Amazon SageMaker:** is a fully-managed service that enables data scientists and developers to quickly and easily build, train, and deploy machine learning models at any scale.  

NACL |Security Group
------------ | -------------
NACL can be understood as the firewall for the subnet | Security group can be understood as a firewall to protect EC2 instances
Stateless, meaning any change applied to an incoming rule isn’t automatically applied to an outgoing rule | Stateful, any changes which are applied to an incoming rule is automatically applied to an outgoing rule

What are the different types of EC2 instances?  
There 5 different types of EC2 instances: general purpose, compute-optimized, memory-optimized, storage-optimized, accelerated computing. Know each.

----------------------------

## Software Testing:
There are many approaches available in [software testing](https://en.wikipedia.org/wiki/Software_testing). Reviews, walkthroughs, or inspections are referred to as static testing(verification), whereas executing programmed code with a given set of test cases is referred to as [dynamic testing](https://en.wikipedia.org/wiki/Dynamic_testing)(validation)

Automation Testing: Selenium and Katalon Studio

### White Box Testing:
an internal perspective of the system, as well as programming skills, are used to design test cases. This testing is usually done at the unit level.
- [API testing](https://en.wikipedia.org/wiki/API_testing): testing of the application using public and private APIs (application programming interfaces)
- [Code coverage](https://en.wikipedia.org/wiki/Code_coverage): creating tests to satisfy some criteria of code coverage (e.g., the test designer can create tests to cause all statements in the program to be executed at least once)
- [Fault injection methods](https://en.wikipedia.org/wiki/Fault_injection): intentionally introducing faults to gauge the efficacy of testing strategies
- [Mutation testing methods](https://en.wikipedia.org/wiki/Mutation_testing)
- [Static testing methods](https://en.wikipedia.org/wiki/Static_testing)

### Black Box Testing:
testing method in which testers evaluate the functionality of the software under test without looking at the internal code structure.
- Black-box testing methods include: equivalence partitioning, boundary value analysis, all-pairs testing, state transition tables, decision table testing, fuzz testing, model-based testing, use case testing, exploratory testing, and specification-based testing.
It can be applied to all levels of software testing, usually used at higher levels.

### Grey Box Testing:
involves having knowledge of internal data structures and algorithms for purposes of designing tests while executing those tests at the user, or black-box level.

## Testing Levels: 
1. Unit Testing
	- Unit testing refers to tests that verify the functionality of a specific section of code, usually at the function level. In an object-oriented environment, this is usually at the class level, and the minimal unit tests include the constructors and destructors. 
	- Unit testing might include static code analysis, data-flow analysis, metrics analysis, peer code reviews, code coverage analysis and other software testing practices.

2. Integration Testing
	Integration Testing is the process of testing the connectivity or data transfer between a couple of unit tested modules.
	
3. System Testing
	A completely integrated system to verify that the system meets its requirements. For example, a system test might involve testing a login interface, then creating and editing an entry, plus sending or printing results, followed by summary processing or deletion (or archiving) of entries, then logoff.

4. Acceptance Testing 
	Operational readiness of the system to be supported and integrated. Final Step to see if it doesn’t break anything else.

## Testing types, techniques and tactics:

Installation testing: self explanatory

**Compatibility** testing: 
	- Testing compatibility with other applications or OS or versions.
	
**Smoke** and **Sanity** testing: 
- Sanity testing determines whether or not to test further
- Smoke testing consists of minimal attempts to operate the software

**Regression testing:**
	- Method for finding defects after a major code change. To find regressions (degraded or lost features). 

**Acceptance testing:**
	- A smoke test or acceptance testing by the customer.

**Alpha/beta testing:** user acceptance testing by the customer/ testers

**Functional** vs **non-functional** testing: test if it fits specifications vs performance and scalability

**Continuous** testing: using automated tests as part of the delivery pipeline

**Destructive** testing: attempts to cause the software to fail

Talk to me about which debuggers/testing software you have used in order to fix programming errors?  
- Python assert()
- VS Code
- Pypy
- Mypy

Test Driven Development: (develop tests before coding)
- Cypress
- jest  
https://www.youtube.com/watch?v=Jv2uxzhPFl4&list=PLIin1ELTMmjYRmbQo_fYwU2vWtaK5CXxp&index=35

------------------------------------------------

## Parallel Processing:
> Multiple processes done in separate memory locations
Both processes and threads are independent sequences of execution. The typical difference is that threads (of the same process) run in a shared memory space, while processes run in separate memory spaces.
- A [Fork](https://en.wikipedia.org/wiki/Fork_(system_call)) is when a process creates a copy of itself.

### Process
Each [process](https://en.wikipedia.org/wiki/Process_(computing)) provides the resources needed to execute a program. A process has a virtual address space, executable code, open handles to system objects, a security context, a unique process identifier, environment variables, a priority class, minimum and maximum working set sizes, and at least one thread of execution. Each process is started with a single thread, often called the primary thread, but can create additional threads from any of its threads.

### Thread
A thread is an entity within a process that can be scheduled for execution. All threads of a process share its virtual address space and system resources. In addition, each thread maintains exception handlers, a scheduling priority, thread local storage, a unique thread identifier, and a set of structures the system will use to save the thread context until it is scheduled. The thread context includes the thread's set of machine registers, the kernel stack, a thread environment block, and a user stack in the address space of the thread's process. Threads can also have their own security context, which can be used for impersonating clients.

Concurrency:
https://en.wikipedia.org/wiki/Concurrency_(computer_science)

Daemon:
https://en.wikipedia.org/wiki/Daemon_(computing)

### ASYNC Await
- Async makes a function return a Promise
- Await makes a function wait for a Promise
Fake synchronous checks if we are not breaking the execution thread

A **Promise** is a proxy for a value not necessarily known when the promise is created. It allows you to associate handlers with an asynchronous action's eventual success value or failure reason. This lets asynchronous methods return values like synchronous methods: instead of immediately returning the final value, the asynchronous method returns a promise to supply the value at some point in the future.

A **Promise** is in one of these states:
- Pending: initial state, neither fulfilled nor rejected.
- Fulfilled: meaning that the operation was completed successfully.
- Rejected: meaning that the operation failed.

Consider the standard producer-consumer problem. Assume, we have a buffer of 4096-byte length. A producer thread collects the data and writes it to the buffer. A consumer thread processes the collected data from the buffer. The objective is, both the threads should not run at the same time. 

Using **Mutex**: 
- A **mutex** provides mutual exclusion, either producer or consumer can have the key (mutex) and proceed with their work. As long as the buffer is filled by the producer, the consumer needs to wait, and vice versa. 
- At any point of time, only one thread can work with the entire buffer. The concept can be generalized using **semaphore**. 

Using **Semaphore**: 
- A semaphore is a generalized mutex. In lieu of a single buffer, we can split the 4 KB buffer into four 1 KB buffers (identical resources). A semaphore can be associated with these four buffers. The consumer and producer can work on different buffers at the same time.

A **mutex** is a locking mechanism used to synchronize access to a resource. Only one task (can be a thread or process based on OS abstraction) can acquire the mutex. It means there is ownership associated with a mutex, and only the owner can release the lock (mutex). 

**Semaphore** is a signaling mechanism (“I am done, you can carry on” kind of signal). For example, if you are listening to songs (assume it as one task) on your mobile phone and at the same time, your friend calls you, an interrupt is triggered upon which an interrupt service routine (ISR) signals the call processing task to wake up. 

-----------------------------------------------------

## System Design preparation:

This section is more of a high level view of some important things to know about database design and software design. You may get a more in depth system design focused interview where you are asked to design a product or fix/improve one.  
[Here is a useful repo for a system design interview](https://github.com/donnemartin/system-design-primer)

![system design overview](https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67)

### ACID
- Atomicity - each transaction is a single unit (fails or succeeds completely)
- Consistency - a transaction can only bring the database from one valid state to another
- Isolation - all transactions in a concurrent stream get executed fully
- Durability - once a transaction has been committed it will remain so

### CAP Theorem for distributed computing
this states that it is not possible for a distributed computer system to simultaneously provide all three of the following guarantees:
- **Consistency** (all nodes see the same data even at the same time with concurrent updates )
- **Availability** (a guarantee that every request receives a response about whether it was successful or failed)
- **Partition tolerance** (the system continues to operate despite arbitrary message loss or failure of part of the system)

### Code Reusability
Candidate design features for software reuse include:
- [Adaptable](https://en.wikipedia.org/wiki/Adaptability)
- Brief: small size
- [Consistency](https://en.wikipedia.org/wiki/Consistency)
- [Correctness](https://en.wikipedia.org/wiki/Correctness_(computer_science))
- [Extensibility](https://en.wikipedia.org/wiki/Extensibility)
- Fast
- Flexible
- Generic
- Localization of volatile (changeable) design assumptions (David Parnas)
- [Modularity](https://en.wikipedia.org/wiki/Modularity_(programming))
- [Orthogonality](https://en.wikipedia.org/wiki/Orthogonality)
- Parameterization
- Simple: low complexity
- Stability under changing requirements

## SOLID

### Single Responsibility Principle (SRP)
This principle states that there should never be more than one reason for a class to change. This means that you should design your classes in such a way that each class should have a single purpose.
- Ex: An Account class is responsible for managing Current and Saving Account but a CurAccount and a SavingAccount classes are specialized. Hence both are responsible for a single purpose only.

### Open/Closed Principle (OCP)
This principle states that software entities (classes, modules, functions, etc.) should be open for extension but closed for modification. The "closed" part of the rule states that once a module has been developed and tested, the code should only be changed to correct bugs. The "open" part says that you should be able to extend existing code in order to introduce new functionality.
- Ex: A PaymentGateway base class contains all basic payment related properties and methods. This class can be extended by different PaymentGateway classes for different payment gateway vendors to achieve their functionalities. Hence it is open for extension but closed for modification.

### Liskov Substitution Principle (LSP)
This principle states that functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.
- Ex: Assume that you have an inheritance hierarchy with Person and Student. Wherever you can use Person, you should also be able to use a Student, because Student is a subclass of Person.

### Interface Segregation Principle (ISP)
This principle states that Clients should not be forced to depend upon interfaces that they don’t use. This means the number of members in the interface that is visible to the dependent class should be minimized.

### Dependency Inversion Principle (DIP)
- High level modules should not depend upon low level modules. Both should depend upon abstractions.
- Abstractions should not depend upon details. Details should depend upon abstractions.
- It helps us to develop loosely coupled code by ensuring that high-level modules depend on abstractions rather than concrete implementations of lower-level modules. The Dependency Injection pattern is an implementation of this principle

### DRY (Don’t Repeat Yourself)
This principle states that each small piece of knowledge (code) may only occur exactly once in the entire system. This helps us to write scalable, maintainable and reusable code.

-------------------------------------------

## Statistics and Probability 
https://www.khanacademy.org/math/statistics-probability

**Permutations:**
> Abc, bca, bac, cav, cba, acbb = 3! => n!
> PEPPER = 6! / (3!2!)
> n!/(n1!)


**Combinations:** n choose r  
*(n r)  for r<=n => n! / ((n-r)!r!)*

Binomial Theorem

De Morgan’s Laws: 
>	(E U F)^c = E^cF^c
>	(EF)^c = E^c U Fc

**Probability:** P(E) = (num of outcomes in E) / (num of outcomes in S)

**Conditional Probability:**  
	P(E|F) = probability  E occurs given F
	
What is Bayes theorem?  
P(A|B) = P(A) P(B|A) / P(B)

----------------------------
What is the diff between precision/specificity

Quantile: value under which a certain percent lies

Dispersion -> Variance: average of the squared deviation from the mean 
(subtract the mean and square the result, then find the average of those differences)

[Standard deviation](https://www.mathsisfun.com/data/standard-deviation.html) = variance

https://www.youtube.com/watch?v=zRUliXuwJCQ&list=WL&index=9  

https://www.youtube.com/watch?v=mBCiKUzwdMs&list=WL&index=88

https://www.youtube.com/watch?v=HZGCoVF3YvM&list=WL&index=11  

https://www.youtube.com/watch?v=BrK7X_XlGB8&list=WL&index=10  

------------------------------

## Distributions:
https://en.wikipedia.org/wiki/Binomial_distribution

**Probability Density Function (PDF)** := the probability of seeing a value in a certain interval equals the integral of the density function over the interval

**Cumulative Distribution Function (CDF)** := the probability that a random variable is <= a value

**Normal distribution:** 
	A continuous probability distribution that is symmetric about the mean (Bell curve).

**Variance** = how scattered the predictions are from the actual value
High variance means overfitting

**Correlation** measures how strongly two variables are related.
- In covariance two items vary together and it’s a measure that indicates the extent to which two random variables change in tandem
  
**Error** = bias + variance

**Bias** = how far the predicted values are from the actual values

High bias means you are underfitting

----------------------------------------
## Data

### Analysis types

**Univariate analysis** is the simplest and easiest form of data analysis where the data being analyzed contains only one variable. 
- Example - Studying the heights of players in the NBA.
- Univariate analysis can be described using Central Tendency, Dispersion, Quartiles, Bar charts, Histograms, Pie charts, and Frequency distribution tables.

**Bivariate analysis** involves the analysis of two variables to find causes, relationships, and correlations between the variables. 
- Example – Analyzing the sale of ice creams based on the temperature outside.
- The bivariate analysis can be explained using Correlation coefficients, Linear regression, Logistic regression, Scatter plots, and Box plots.

**Multivariate analysis** involves the analysis of three or more variables to understand the relationship of each variable with the other variables. 
- Example – Analysing Revenue based on expenditure.
- Multivariate analysis can be performed using Multiple regression, Factor analysis, Classification & regression trees, Cluster analysis, Principal component analysis, Dual-axis charts, etc.

**A/B testing** (also known as split testing or bucket testing) is a method of comparing two versions of a webpage or app against each other to determine which one performs better. AB testing is essentially an experiment where two or more variants of a page are shown to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal.


### Hypothesis Testing:
a hypothesis that is testable on the basis of observed data modelled as the realised values taken by a collection of random variables.[1] A set of data is modelled as being realised values of a collection of random variables having a joint probability distribution in some set of possible joint distributions. The hypothesis being tested is exactly that set of possible probability distributions. 

A **statistical hypothesis** test is a method of [statistical inference](https://en.wikipedia.org/wiki/Statistical_inference). An alternative hypothesis is proposed for the probability distribution of the data, either explicitly or only informally. The comparison of the two models is deemed statistically significant if, according to a threshold probability—the significance level—the data would be unlikely to occur if the [null hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis) were true. A hypothesis test specifies which outcomes of a study may lead to a rejection of the null hypothesis at a pre-specified level of significance, while using a pre-chosen measure of deviation from that hypothesis (the test statistic, or goodness-of-fit measure). The pre-chosen level of significance is the maximal allowed "false positive rate". One wants to control the risk of incorrectly rejecting a true null hypothesis.

## Data Cleaning:

How can you handle missing values in a dataset?
- **Listwise Deletion**
	- In the listwise deletion method, an entire record is excluded from analysis if any single value is missing.
- **Average Imputation**
	- Take the average value of the other participants' responses and fill in the missing value.
- **Regression Substitution**
	- You can use multiple-regression analyses to estimate a missing value.
- **Multiple Imputations**
	- It creates plausible values based on the correlations for the missing data and then averages the simulated datasets by incorporating random errors in your predictions.

How do you deal with outliers in a dataset?
- Trim them out
- Normalize them (log+1)

### Dataset validation
**Field Level Validation** 
– In this method, data validation is done in each field as and when a user enters the data. It helps to correct the errors as you go.

**Form Level Validation** 
– In this method, the data is validated after the user completes the form and submits it. It checks the entire data entry form at once, validates all the fields in it, and highlights the errors (if any) so that the user can correct it. 

**Data Saving Validation** 
– This data validation technique is used during the process of saving an actual file or database record. Usually, it is done when multiple data entry forms must be validated. 

**Search Criteria Validation** 
– This validation technique is used to offer the user accurate and related matches for their searched keywords or phrases. The main purpose of this validation method is to ensure that the user’s search queries can return the most relevant results.

---------------------------------------------

## ML Prep:
<img align="center" width="100" height="100" src="https://media2.giphy.com/media/Uu5MHCPoCabaLUYUgE/200w.webp?cid=ecf05e47map8im7jvjhwyl4r0xfd6apx38pksmtcwy4aipjd&rid=200w.webp&ct=g">

https://developers.google.com/machine-learning/crash-course  

https://www.youtube.com/watch?v=1-myowrUhok&list=PLIin1ELTMmjYRmbQo_fYwU2vWtaK5CXxp&index=36  

Possible Interview Topics:
> Statistical distributions
> Probability simulation
> String parsing and data manipulation
> Numpy functions and matrices
> Pandas data munging
> A project walkthrough

[An ML roadmap](https://whimsical.com/CA7f3ykvXpnJ9Az32vYXva)   
https://www.springboard.com/blog/machine-learning-interview-questions/  
https://www.edureka.co/blog/interview-questions/data-science-interview-questions/  

### Precision vs recall
- Recall is the true positive rate (pos claims vs actual num of pos)- rate of fish caught in pond
- Precision is the positive predictive value - rate of correct predictions

**F1 Score:**  
	A weighted average of the precision and recall of a model (1 best, 0 worst)

### Evaluation metrics:
- Classification
	- Accuracy
	- Precision
	- Recall
	- Confusion matrix
	- F1 score
	- Mean average precision (MAP) - object detection
	- Jaccard index
- Regression
	- RMSE / RMSECV
	- MAE
	- R^2

### Supervised Algorithms:
- Linear Regression
- Logistic Regression
- k-Nearest Neighbors
- Support Vector Machines (SVM)
- Decision Trees and Random Forest
- AdaBoost and Gradient boosting
	- XGBoost
	- CatBoost
	-  LightGBM
- Neural Networks
	- Convolutional
	- Recurrent (RNN)
	- Transformer

### Unsupervised Algorithms:
- Clustering (K-Means)
- Visualization and dimensionality reduction
	- PCA
	- Autoencoders
	- t-Distributed Stochastic Neighbor Embedding(t-SNE)
- Anomaly Detection
	- Autoencoder
	- One-class classification

What is the difference between supervised vs unsupervised machine learning?

What is the difference between **discriminative** and **generative** models?
- **Discriminative**
	- Learn decision boundaries (ex: svm, regressions)
- **Generative**
	- Learn distributions (ex: naive bayes)

Time series:  
	K-fold cv  

**Variance** = how scattered the predictions are from the actual value  
High variance means overfitting  

**Correlation** measures how strongly two variables are related.  
In covariance two items vary together and it’s a measure that indicates the extent to which two random variables change in cycle  

**Error** = bias + variance  
**Bias** = how far the predicted values are from the actual values  
High bias means you are underfitting

How to deal with **underfitting**:
- Add features
- Decrease regularization term  
How to deal with **overfitting**:
- Reduce number of features
- Increase regularization term
- Dropout- randomly remove parts of your model
- Data Augmentation
- Batch  normalization

Regularization is a technique where we penalize the loss function for flexibility  
            **L1 and L2 regularization:**  
L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting. L1 corresponds to setting a Laplacean prior on the terms, while L2 corresponds to a Gaussian prior.

Type 1 error is a false positive  
Type 2 error is a false negative  

**What is deep learning,** and how does it contrast with other machine learning algorithms?  
  	Deep learning is a subset of machine learning that is concerned with neural networks: how to use backpropagation and certain principles from neuroscience to more accurately model large sets of unlabelled or semi-structured data. In that sense, deep learning represents an unsupervised learning algorithm that learns representations of data through the use of neural nets.

**Convolutional Neural Network:**
  	a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.  
https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53

What cross-validation technique would you use on a time series dataset?  
  K-folds with forward chaining. As it is inherently ordered by date and is biased towards the later dates

How would you build a data pipeline?  

How would you implement a recommendation system?  

-------------------------------------------

### NLP
    
Statistical: Part of Speech tagging, decision trees  
Neural Networks: word embeddings, NER, bert  

### Morphological analysis
[Lemmatization](https://en.wikipedia.org/wiki/Lemmatisation)  
The task of removing inflectional endings only and to return the base dictionary form of a word which is also known as a lemma. Lemmatization is another technique for reducing words to their normalized form. But in this case, the transformation actually uses a dictionary to map words to their actual form

[Morphological segmentation](https://en.wikipedia.org/wiki/Morphology_(linguistics))  
Separate words into individual morphemes and identify the class of the morphemes.

[Part-of-speech tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging)  
Given a sentence, determine the part of speech (POS) for each word. Many words, especially common ones, can serve as multiple parts of speech. For example, "book" can be a noun ("the book on the table") or verb ("to book a flight"); "set" can be a noun, verb or adjective; and "out" can be any of at least five different parts of speech.

[Stemming](https://en.wikipedia.org/wiki/Stemming)  
The process of reducing inflected (or sometimes derived) words to a base form (e.g., "close" will be the root for "closed", "closing", "close", "closer" etc.). Stemming yields similar results as lemmatization, but does so on grounds of rules, not a dictionary.

[Named entity recognition](https://en.wikipedia.org/wiki/Named_entity_recognition) (NER)  
Given a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization). Although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity, and in any case, is often inaccurate or insufficient. For example, the first letter of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized. Furthermore, many other languages in non-Western scripts (e.g. Chinese or Arabic) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names. For example, German capitalizes all nouns, regardless of whether they are names, and French and Spanish do not capitalize names that serve as adjectives.

[Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) (see also [Multimodal sentiment analysis](https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis))  
Extract subjective information usually from a set of documents, often using online reviews to determine "polarity" about specific objects. It is especially useful for identifying trends of public opinion in social media, for marketing.

BERT: https://www.kaggle.com/mdfahimreshm/bert-in-depth-understanding

SPACY: https://spacy.io/

[Link to top](table-of-contents)

===========================================================
## TODO <img src="https://media.giphy.com/media/VgCDAzcKvsR6OM0uWg/giphy.gif" width="50">
- add more images and resize them
- add to ci/cd section and jenkins
- add spark and kafka section
- add Hadoop Section
- add springboot and maven to Java
- add react section
